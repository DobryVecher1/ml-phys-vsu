{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.read_csv('data\\\\healthcare-dataset-stroke-data.csv', index_col='id')\n",
    "\n",
    "X = df.drop(columns=['stroke'])\n",
    "y = df['stroke'].copy()\n",
    "\n",
    "X['gender'] = X['gender'].map({'Male': 1, 'Female': 0, 'Other': 1})\n",
    "X['Residence_type'] = X['Residence_type'].map({'Urban': 1, 'Rural': 0})\n",
    "X['ever_married'] = X['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "X = pd.get_dummies(X, columns=['work_type', 'smoking_status'], dtype=float)\n",
    "X['bmi'] = X['bmi'].fillna(value=X['bmi'].median())\n",
    "\n",
    "# Train/val split\n",
    "obj_ind = X.index.tolist()\n",
    "np.random.shuffle(obj_ind)\n",
    "num_train = int(0.8*len(obj_ind))\n",
    "\n",
    "X_train, y_train = X.loc[obj_ind[:num_train], :], y[obj_ind[:num_train]]\n",
    "X_val, y_val = X.loc[obj_ind[num_train:], :], y[obj_ind[num_train:]]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация Градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, num_trees=100, max_depth=2, lr=0.1):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.lr = lr\n",
    "        self.trees_list = []\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return (1/(1 + np.exp(-x)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def ce_loss(y_true, probs, get_grad=False):\n",
    "        if get_grad:\n",
    "            return -y_true/(probs+1e-8) + (1-y_true)/(1-probs+1e-8) \n",
    "        else:\n",
    "            return -y_true*np.log(probs) - (1-y_true)*np.log(1-probs)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # initial prediction\n",
    "        preds_raw = np.zeros(len(X_train))\n",
    "        probs = GradientBoosting.sigmoid(preds_raw)\n",
    "        self.loss_train = []\n",
    "\n",
    "        for ii in range(self.num_trees):\n",
    "            # find anti-gradient\n",
    "            anti_grad = -GradientBoosting.ce_loss(np.array(y_train), probs, get_grad=True)\n",
    "            # train regressor on (X, -g)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, criterion='squared_error')\n",
    "            tree.fit(X_train, anti_grad)\n",
    "            self.trees_list.append(tree)\n",
    "            # calculate raw predictions and probabilities\n",
    "            preds_raw += self.lr * np.array(tree.predict(X_train))\n",
    "            probs = GradientBoosting.sigmoid(preds_raw)\n",
    "            self.loss_train.append(\n",
    "                np.mean(GradientBoosting.ce_loss(np.array(y_train), probs))\n",
    "                )\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        preds_raw = np.zeros(len(X_test))   \n",
    "        for tree in self.trees_list:\n",
    "            preds_raw += self.lr * np.array(tree.predict(X_test))\n",
    "\n",
    "        probs = GradientBoosting.sigmoid(preds_raw)\n",
    "        pred_labels = (np.array(probs) > 0.1).astype(int)\n",
    "\n",
    "        return probs, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# hyperparameter tuning\n",
    "grid = {\n",
    "    'max_depth': list(range(1, 10, 1)),\n",
    "    'num_trees': list(range(50, 200, 20)),\n",
    "}\n",
    "best_metr = 0.0\n",
    "best_param = None\n",
    "param_comb = list(itertools.product(*grid.values()))\n",
    "\n",
    "for comb in param_comb:\n",
    "    gbdt_custom = GradientBoosting(max_depth=comb[0], num_trees=comb[1])\n",
    "    gbdt_custom.fit(X_train, y_train)\n",
    "    preds_probs, preds_labels = gbdt_custom.predict(X_val)\n",
    "\n",
    "    metr = roc_auc_score(y_val, preds_labels)\n",
    "    metr_probs = roc_auc_score(y_val, preds_probs)\n",
    "\n",
    "    # save best metric and parameters\n",
    "    if metr_probs > best_metr:\n",
    "        best_metr = metr_probs.copy()\n",
    "        best_param = comb\n",
    "\n",
    "    print(\"metr: \" , metr)\n",
    "    print(\"metr_prob: \", metr_probs)\n",
    "\n",
    "print(best_metr, best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on best params\n",
    "gbdt_custom = GradientBoosting(max_depth=best_param[0], num_trees=best_param[1])\n",
    "gbdt_custom.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best_metr = 0.0\n",
    "best_param = None\n",
    "\n",
    "# hyperparameter tuning\n",
    "grid = {\n",
    "    'max_depth': list(range(1, 10, 1)),\n",
    "    'n_estimators': list(range(50, 200, 20)),\n",
    "}\n",
    "param_comb = list(itertools.product(*grid.values()))\n",
    "\n",
    "for comb in param_comb:\n",
    "    rf_scikit = GradientBoostingClassifier(max_depth=comb[0], n_estimators=comb[1])\n",
    "    rf_scikit.fit(X_train, y_train)\n",
    "    preds = rf_scikit.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    metr = roc_auc_score(y_val, preds)\n",
    "\n",
    "    if metr > best_metr:\n",
    "        best_metr = metr.copy()\n",
    "        best_param = comb\n",
    "\n",
    "    print(metr)\n",
    "\n",
    "print(best_metr, best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
